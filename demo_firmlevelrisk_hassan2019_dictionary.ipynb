{
 "cells": [
  {
   "cell_type": "code",
   "id": "d0ea3097d1af6588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T03:14:56.931858Z",
     "start_time": "2024-07-20T03:14:38.623719Z"
    }
   },
   "source": [
    "from nlptoolkits.FirmLevelRiskKits import DictionaryT, PreprocessT, ScorerT\n",
    "from nlptoolkits.SmallKits import IOHandlerT\n",
    "import nlptoolkits\n",
    "import pandas as pd\n",
    "import tempfile"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Too few parameters for typing.Dict; actual 1, expected 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnlptoolkits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFirmLevelRiskKits\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DictionaryT, PreprocessT, ScorerT\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnlptoolkits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mSmallKits\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IOHandlerT\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnlptoolkits\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Appfiles\\Dropbox_69449_files\\Dropbox\\Legion5ip\\NUS_RA\\nlptoolkits\\nlptoolkits\\__init__.py:6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SmallKits\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StanzaKits\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FirmLevelRiskKits\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resources\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# out source pack\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# --------------------------------------------------------------------------\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# directly import naive functions, aliases\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# --------------------------------------------------------------------------\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Appfiles\\Dropbox_69449_files\\Dropbox\\Legion5ip\\NUS_RA\\nlptoolkits\\nlptoolkits\\FirmLevelRiskKits\\__init__.py:4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DictionaryT\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _Resources\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ScorerT\n",
      "File \u001B[1;32mD:\\Appfiles\\Dropbox_69449_files\\Dropbox\\Legion5ip\\NUS_RA\\nlptoolkits\\nlptoolkits\\FirmLevelRiskKits\\ScorerT.py:12\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _BasicKits\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mNgramScorer\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     15\u001B[0m                  processes: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m     16\u001B[0m                  token_sep_string: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m CoreNLPServerPack\u001B[38;5;241m.\u001B[39m_GlobalArgs\u001B[38;5;241m.\u001B[39mDEFAULT_TOKEN_SEP_STRING,\n\u001B[0;32m     17\u001B[0m                  n: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     18\u001B[0m                  window_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[0;32m     19\u001B[0m                  ):\n\u001B[0;32m     20\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocesses \u001B[38;5;241m=\u001B[39m processes\n",
      "File \u001B[1;32mD:\\Appfiles\\Dropbox_69449_files\\Dropbox\\Legion5ip\\NUS_RA\\nlptoolkits\\nlptoolkits\\FirmLevelRiskKits\\ScorerT.py:40\u001B[0m, in \u001B[0;36mNgramScorer\u001B[1;34m()\u001B[0m\n\u001B[0;32m     34\u001B[0m     windows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[ngrams[i:] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)]))\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m windows, words\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscorer\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     39\u001B[0m            texture: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m---> 40\u001B[0m            dict_topic_ngram_weighted_map: \u001B[43mtyping\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtyping\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDict\u001B[49m\u001B[43m]\u001B[49m,\n\u001B[0;32m     41\u001B[0m            dict_subject_word_set: typing\u001B[38;5;241m.\u001B[39mOptional[\u001B[38;5;28mset\u001B[39m],\n\u001B[0;32m     42\u001B[0m            is_scale_by_totalwords: \u001B[38;5;28mbool\u001B[39m\n\u001B[0;32m     43\u001B[0m            ):\n\u001B[0;32m     44\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;124;03m    :param texture: [str] texture that cleaned by the PreprocessT\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;124;03m    :param dict_topic_ngram_weighted_map: typing.Dict[typing.Dict] For example, Political.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     57\u001B[0m \n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m     60\u001B[0m     windows, words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ngram_window(texture)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\seminlpclassify38\\lib\\typing.py:261\u001B[0m, in \u001B[0;36m_tp_cache.<locals>.inner\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001B[39;00m\n\u001B[1;32m--> 261\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\seminlpclassify38\\lib\\typing.py:686\u001B[0m, in \u001B[0;36m_GenericAlias.__getitem__\u001B[1;34m(self, params)\u001B[0m\n\u001B[0;32m    684\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameters to generic types must be types.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    685\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(_type_check(p, msg) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params)\n\u001B[1;32m--> 686\u001B[0m \u001B[43m_check_generic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _subs_tvars(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__parameters__, params)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\seminlpclassify38\\lib\\site-packages\\typing_extensions.py:165\u001B[0m, in \u001B[0;36m_check_generic\u001B[1;34m(cls, parameters, elen)\u001B[0m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (num_tv_tuples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (alen \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m elen \u001B[38;5;241m-\u001B[39m num_tv_tuples):\n\u001B[0;32m    164\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 165\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToo \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmany\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39malen\u001B[38;5;250m \u001B[39m\u001B[38;5;241m>\u001B[39m\u001B[38;5;250m \u001B[39melen\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfew\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m parameters for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    166\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m actual \u001B[39m\u001B[38;5;132;01m{\u001B[39;00malen\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, expected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00melen\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: Too few parameters for typing.Dict; actual 1, expected 2"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "86b78b422d1539cb",
   "metadata": {},
   "source": [
    "We make the basic classes for further use"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfd0b21e560eb4fd",
   "metadata": {},
   "source": [
    "internation_tax_dictionary = IOHandlerT.file_to_list(\n",
    "    './input_data/annotatedsent_Principles_of_International_Taxation.txt',\n",
    "    charset_error_encoding='utf-8'\n",
    ")[:1000]\n",
    "\n",
    "tweets_texture = IOHandlerT.file_to_list(\n",
    "    './input_data/tweets_origin.txt',\n",
    "    charset_error_encoding='utf-8'\n",
    ")[:1000]\n",
    "\n",
    "# make a class to clean the data(dict)\n",
    "corenlp_preprocess_cls = PreprocessT.NgramDataPreprocessor(\n",
    "    # remove_stopwords_set=nlptoolkits.resources.SET_STOPWORDS\n",
    ")\n",
    "\n",
    "# make a class to build the dictionary\n",
    "corenlp_ngram_dict_cls = DictionaryT.NgramDictionaryBuilder(\n",
    "    # remove_stopwords_set=nlptoolkits.resources.SET_STOPWORDS\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234b1a756f30e9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:04.449625Z",
     "start_time": "2024-07-19T15:20:04.436103Z"
    }
   },
   "source": [
    "internation_tax_dictionary[:3]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b659065130481dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:04.464753Z",
     "start_time": "2024-07-19T15:20:04.451624Z"
    }
   },
   "source": [
    "tweets_texture[:3]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc9200b4ee6e404",
   "metadata": {},
   "source": [
    "Part to make Ngram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca073692c8d323fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T03:14:56.935839Z",
     "start_time": "2024-07-20T03:14:56.935839Z"
    }
   },
   "source": [
    "international_tax_tfidf = corenlp_ngram_dict_cls.n_gramizer_dictionary_builder(\n",
    "    internation_tax_dictionary, scorer = 'tfidf', \n",
    "    final_remove_token_lessequal_then_length=1\n",
    "    )\n",
    "international_tax_tfidf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84076d3660b64472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:08.365321Z",
     "start_time": "2024-07-19T15:20:08.335580Z"
    }
   },
   "source": [
    "international_tax_tfidf"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f983ad9d68c9492d",
   "metadata": {},
   "source": [
    "You can remove words by remove phrases which are in another dictionary, but we do not do here now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa82a77a4e3d63",
   "metadata": {},
   "source": [
    "We now clean the tweets data quickly by using the nltk quick cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d7b214c4145b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:10.643119Z",
     "start_time": "2024-07-19T15:20:08.367332Z"
    }
   },
   "source": [
    "PreprocessT.naive_nltk_annotator(\n",
    "    tweets_texture,\n",
    "    processes=1\n",
    ")[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd767f27868229a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:35.439616Z",
     "start_time": "2024-07-19T15:20:10.644624Z"
    }
   },
   "source": [
    "tweets_texture_cleaned = corenlp_preprocess_cls.clean_annotated_texture_list(PreprocessT.naive_nltk_annotator(\n",
    "    tweets_texture,\n",
    "    processes=5\n",
    "), processes=5, final_remove_token_lessequal_then_length=1)\n",
    "tweets_texture_cleaned[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "13051651",
   "metadata": {},
   "source": [
    "Actually you could also use the StanfordNLP cleaner to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d601568c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:54.891728Z",
     "start_time": "2024-07-19T15:20:35.441617Z"
    }
   },
   "source": [
    "corenlp_preprocess_cls.alias_auto_clean_annotated_txt(\n",
    "    processes=5,\n",
    "    path_in_parsed_txt='./input_data/annotatedsent_Principles_of_International_Taxation.txt',\n",
    "    path_out_cleaned_txt='./input_data/annotatedsent_Principles_of_International_Taxation_cleaned.txt',\n",
    "    final_remove_token_lessequal_then_length=1\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "60a4f28356ff3e6b",
   "metadata": {},
   "source": [
    "Then we can try to give a score. we have some already known subject set like \"Risk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac35932b4c3c1b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:54.907789Z",
     "start_time": "2024-07-19T15:20:54.893725Z"
    }
   },
   "source": [
    "nlptoolkits.resources.SET_OXFORD_SYNONYMS_RISK_WORDS_LOWER"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cd97ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T15:20:54.923071Z",
     "start_time": "2024-07-19T15:20:54.909883Z"
    }
   },
   "source": [
    "scorer_cls = ScorerT.NgramScorer(processes=5)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scorer_cls.scorer(\n",
    "    tweets_texture_cleaned[2],\n",
    "    topic_ngram_weighted_map_dict={'globtax':international_tax_tfidf},\n",
    "    subject_word_set_dict={'risk':nlptoolkits.resources.SET_OXFORD_SYNONYMS_RISK_WORDS_LOWER,\n",
    "                           'sentpos':nlptoolkits.resources.SET_LOUGHRAN_MCDONALD_POSITIVE_WORDS_LOWER,\n",
    "                           'sentneg':nlptoolkits.resources.SET_LOUGHRAN_MCDONALD_NEGATIVE_WORDS_LOWER,\n",
    "                           },\n",
    "    is_scale_by_totalwords=True,\n",
    "    binary_transformation_subjects=['sentpos'],\n",
    "    scale_multiplier=100000\n",
    ")"
   ],
   "id": "3d2252981d0c617c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "set(['risk'])",
   "id": "a4d7179553e117ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Batch run ->",
   "id": "9426b01ab82852df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rsts_tp = scorer_cls.list_scorer(\n",
    "    tweets_texture_cleaned,\n",
    "    topic_ngram_weighted_map_dict={'globtax':international_tax_tfidf},\n",
    "    subject_word_set_dict={'risk':nlptoolkits.resources.SET_OXFORD_SYNONYMS_RISK_WORDS_LOWER,\n",
    "                           'sentpos':nlptoolkits.resources.SET_LOUGHRAN_MCDONALD_POSITIVE_WORDS_LOWER,\n",
    "                           'sentneg':nlptoolkits.resources.SET_LOUGHRAN_MCDONALD_NEGATIVE_WORDS_LOWER,\n",
    "                           },\n",
    "    is_scale_by_totalwords=True,\n",
    "    binary_transformation_subjects=['risk'],\n",
    "    scale_multiplier=100000\n",
    ")"
   ],
   "id": "f9495d4ba58ac83d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pd.DataFrame(rsts_tp)",
   "id": "2b1406fecee528fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
