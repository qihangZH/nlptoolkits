{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "from nlptoolkits.SmallKits import BitermplusT, LangDetectT\n",
    "from nlptoolkits.resources import SET_STOPWORDS\n",
    "import nltk\n",
    "import pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we firstly read the data and prepare to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    texts = pd.read_excel('./input_data/btm_sample_data.xlsx',\n",
    "                            engine='openpyxl', \n",
    "                            usecols = ['id', 'text_without_mentioned_user']\n",
    "                        )['text_without_mentioned_user'].to_list()\n",
    "    # stanza stopwords(stanford core nlp, english)\n",
    "    stopwords = list(set(list(SET_STOPWORDS) + nltk.corpus.stopwords.words('english')))\n",
    "    topic_num = 20\n",
    "    lang_list = LangDetectT.detect_seq_language_list(texts, loop_method='mp', result_type='all')\n",
    "    lang_list\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the None Arabic comments only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "arabic_language_codes_set = set(['ar', 'arz', 'apc', 'ary', 'apd', 'afb', 'acm', 'ayh'])\n",
    "texts = pd.Series(texts)[pd.Series(lang_list).apply(lambda x: set(x).isdisjoint(arabic_language_codes_set))].to_list()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "btmtopic_cls = BitermplusT.BtmTopic(train_text_list=texts, stop_words = stopwords)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, then we use fit-transform to get the result we want, it also will make a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "btmtopic_cls.fit_transform(seed=12321, T=topic_num, M=20, alpha=50/8, beta=0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "btmtopic_cls.model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though, we do not need to use fit-transform for fit is enough, we then use the trained model to have the topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "btmtopic_cls.get_top_topic_words(words_num=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "btmtopic_cls.get_top_topic_docs(text_list=texts, docs_num=10)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nusnlp38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
