import shutil

import html2text
import re
import PyPDF2
import pypandoc
import warnings
import typing
import subprocess
import tempfile
import bs4
import os
import warnings
import readability

import pdf2image

from .. import _BasicKits

# --------------------------------------------------------------------------
# _BasicKits naive readers, aliases
# --------------------------------------------------------------------------

from .._BasicKits.FileT import file_to_list

# --------------------------------------------------------------------------
# _BasicKits naive Writers, aliases
# --------------------------------------------------------------------------

from .._BasicKits.FileT import list_to_file, base64_to_file, write_dict_to_csv


# --------------------------------------------------------------------------
# Basic functions
# --------------------------------------------------------------------------

def __sep_letter_warning():
    warnings.warn(
        """
        The converter names like 'convert_<...>_to_single_line_str' you using may occurs problems like:
        l o w i n g the salary w i l l m a k e t h e worker a r g u i n g t h e c o m p a n y.
        IF you want to correct this problem,
        you have to use nlptoolkits/SmallKits/WordninjaT/replace_sequence_letters_to_words_str
        """
    )


def __so_many_processes_warning(func_name: str):
    warnings.warn(
        f"""
        Warning: If multi-threads/processes used by This type of function-{func_name}
        will be unstable or dead under so-many-threadings.
        It is recommend to use small processes/threads under the problem.
        Like no-more then 4 threads/processes, but this depend on your computer.
        """
    )


# --------------------------------------------------------------------------
# OCR functions
# --------------------------------------------------------------------------
def _ocr_pdf_to_text(pdf_file_path, start_index: int = 0, end_index: typing.Optional[int] = None,
                     temp_image_suffix='PNG', **kwargs):
    __so_many_processes_warning(_ocr_pdf_to_text.__name__)

    kwargs['timeout'] = kwargs['timeout'] if 'timeout' in kwargs else 60

    pdf_file_posix_path = _BasicKits._BasicFuncT.get_absolute_posix_path(pdf_file_path)

    # get pure name
    pdf_pure_name = os.path.splitext(os.path.basename(pdf_file_posix_path))[0]

    # Convert PDF to image
    pages = pdf2image.convert_from_path(pdf_file_path, **kwargs)

    # Extract text from each page using Tesseract OCR
    text_data = ''

    # Loop through each page in the PDF and add the result_text to the string
    end_index = end_index if end_index else len(pages)

    # Prepare environment for the subprocess with adjusted OMP thread limit.
    env = dict(os.environ, OMP_THREAD_LIMIT='1')

    for i, page in enumerate(pages[start_index:end_index]):
        # Using a temporary directory to store intermediate files
        with tempfile.TemporaryDirectory() as temp_dir:

            temp_image_file_path = _BasicKits._BasicFuncT.get_absolute_posix_path(
                os.path.join(temp_dir, f"{pdf_pure_name}_{i}.{temp_image_suffix}")
            )

            temp_text_file_path = _BasicKits._BasicFuncT.get_absolute_posix_path(
                os.path.join(temp_dir, f"{pdf_pure_name}_{i}.txt")
            )

            page.save(temp_image_file_path, temp_image_suffix)

            # Prepare the command to run Tesseract and specify the output base for text (no extension)
            command = ['tesseract', temp_image_file_path, re.search(r'^(.+)\.txt$',
                                                                    temp_text_file_path,
                                                                    flags=re.IGNORECASE | re.DOTALL
                                                                    ).groups()[0]]

            # Run the command and wait for it to complete
            process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
            stdout, stderr = process.communicate()  # Waits for process to complete
            # Check for errors from Tesseract
            if process.returncode != 0:
                error_message = stderr.decode('utf-8')
                raise RuntimeError(f"Error running Tesseract: {error_message}")

            # Read the content of the text file generated by Tesseract
            _txt_encode = _BasicKits._BasicFuncT.find_file_encoding(temp_text_file_path) \
                if _BasicKits._BasicFuncT.find_file_encoding(temp_text_file_path) else 'utf-8'

            with open(temp_text_file_path, 'r', encoding=_txt_encode) as file:
                text = file.read()

            text_data += text + '\n'

    # Return the text data
    return text_data


def _ocr_image_to_text(image_file_path):
    """
    Use tessaract to extract text from an image file
    Args:
        image_file_path: a image file path
    Returns:
        text: the text of the image
    """
    __so_many_processes_warning(_ocr_image_to_text.__name__)

    # Extract text from each page using Tesseract OCR
    text_data = ''

    # Prepare environment for the subprocess with adjusted OMP thread limit.
    env = dict(os.environ, OMP_THREAD_LIMIT='1')

    image_file_posix_path = _BasicKits._BasicFuncT.get_absolute_posix_path(image_file_path)

    image_pure_name = os.path.splitext(os.path.basename(image_file_posix_path))[0]

    # Using a temporary directory to store intermediate files
    with tempfile.TemporaryDirectory() as temp_dir:
        shutil.copy(
            image_file_posix_path,
            os.path.join(temp_dir, f'{image_pure_name}.png')
        )

        temp_text_file_path = _BasicKits._BasicFuncT.get_absolute_posix_path(
            os.path.join(temp_dir, f'{image_pure_name}.txt')
        )

        temp_image_file_path = _BasicKits._BasicFuncT.get_absolute_posix_path(
            os.path.join(temp_dir, f'{image_pure_name}.png')
        )

        # Prepare the command to run Tesseract and specify the output base for text (no extension)
        command = ['tesseract', temp_image_file_path, re.search(r'^(.+)\.txt$',
                                                                temp_text_file_path,
                                                                flags=re.IGNORECASE | re.DOTALL
                                                                ).groups()[0]]

        # Run the command and wait for it to complete
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
        stdout, stderr = process.communicate()  # Waits for process to complete
        # Check for errors from Tesseract
        if process.returncode != 0:
            error_message = stderr.decode('utf-8')
            raise RuntimeError(f"Error running Tesseract: {error_message}")

        # Read the content of the text file generated by Tesseract
        _txt_encode = _BasicKits._BasicFuncT.find_file_encoding(temp_text_file_path) \
            if _BasicKits._BasicFuncT.find_file_encoding(temp_text_file_path) else 'utf-8'

        with open(temp_text_file_path, 'r', encoding=_txt_encode) as file:
            text_data = file.read()

    # Return the text data
    return text_data


# --------------------------------------------------------------------------
# GROBID-NEI-PDF->XML reader
# --------------------------------------------------------------------------
def _tei_xml_to_list(tei_xml_path,
                     tags: typing.Union[list, str],
                     subtags: typing.Optional[typing.Union[list, str]],
                     errors='backslashreplace',
                     **kwargs
                     ):
    """
    read tei-format XML to list of text
    Args:
        tei_xml_path: the path of Tei-xml-path, is a format could be seen in https://tei-c.org/ for detail
        tags: the tag which contain text you interested in, first level, should be ['text'] in default
        subtags: second level tags, like p/s/head, etc

    Returns: a list of text

    """
    if not tags:
        raise ValueError('The tag Could not be NoneLike')
    if isinstance(tags, list):
        # if len(tag) > 1:
        #     warnings.warn('More then one tag will cause replicated result, you should known that')
        pass
    elif isinstance(tags, str):
        tags = [tags]
    else:
        raise ValueError('The tag either be string or list')

    # subtags check
    if subtags:
        if isinstance(subtags, list):
            pass
        elif isinstance(subtags, str):
            subtags = [subtags]
        else:
            raise ValueError('The subtag either be string or list or NoneLike')

    encodetype = _BasicKits._BasicFuncT.find_file_encoding(tei_xml_path) \
        if not _BasicKits._BasicFuncT.find_file_encoding(tei_xml_path) is None else 'utf-8'

    with open(tei_xml_path, 'r', encoding=encodetype, errors=errors) as tei:
        soup = bs4.BeautifulSoup(tei, 'xml')

    # Initialize a list to store <s> pairs from all <div> elements
    s_pairs_list = []
    # for t in tag:
    #     div_elements = soup.find_all(t)
    #
    #     for div in div_elements:
    #         if subtags:
    #
    #             if isinstance(subtags, str):
    #                 subtags = [subtags]
    #
    #             for st in subtags:
    #                 s_elements = div.find_all(st)
    #                 sentences = [s.get_text(strip=True) for s in s_elements]
    #                 s_pairs_list.extend(sentences)
    #         else:
    #             sentences = div.get_text(strip=True)
    #             s_pairs_list.append(sentences)
    """new version use more general way to read the xml"""
    div_elements = soup.find_all(tags)

    for div in div_elements:
        if subtags:
            for st in subtags:
                s_elements = div.find_all(st)
                sentences = [s.get_text(strip=True) for s in s_elements]
                s_pairs_list.extend(sentences)
        else:
            sentences = div.get_text(strip=True)
            s_pairs_list.append(sentences)

    return s_pairs_list


# --------------------------------------------------------------------------
# Readers, ..._to_single_line_str series
# --------------------------------------------------------------------------

def convert_ocrpdf_to_single_line_str(pdf_file_path, start_index: int = 0, end_index: typing.Optional[int] = None,
                                      suppress_warn=False, **kwargs
                                      ):
    """
    Args:
        pdf_file_path: pdf file path
        start_index: the page index to start reading
        end_index: None default, however if not None must be int, the end index
        suppress_warn: is or not raise warning of usage
        kwargs: the argument of pdf2image.convert_from_path
    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s

    """
    if not suppress_warn:
        __sep_letter_warning()
    # Open the PDF file in binary mode
    result_text = _ocr_pdf_to_text(pdf_file_path=pdf_file_path, start_index=start_index, end_index=end_index,
                                   **kwargs
                                   )

    # Remove newline characters to make the result_text a single line
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


def convert_ocrimage_to_single_line_str(image_file_path, suppress_warn=False):
    """
    Args:
        image_file_path: the image file path
        suppress_warn: is or not suppress the warn of sep letter
    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s
    """
    if not suppress_warn:
        __sep_letter_warning()
    # Open the image file in binary mode
    result_text = _ocr_image_to_text(image_file_path)

    # Remove newline characters to make the result_text a single line
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


def convert_teixml_to_single_line_str(tei_xml_path,
                                      tags: typing.Union[list, str] = ['text'],
                                      subtags: typing.Optional[typing.Union[list, str]] = None,
                                      errors='backslashreplace',
                                      sep: str = ' ',
                                      suppress_warn: bool = False,
                                      **kwargs
                                      ):
    """
    :param tei_xml_path: the path of Tei-xml-path, is a format could be seen in https://tei-c.org/ for detail
    :param tags: the tag which contain text you interested in, first level, should be ['text'] in default
    :param subtags: second level tags, like p/s/head, etc
    :param errors: the error handler of open file
    :param sep: the separator of the result text
    :param suppress_warn: is or not suppress the warn of sep letter
    :param kwargs: the argument of bs4.BeautifulSoup
    :return: a list of text
    """
    if not suppress_warn:
        __sep_letter_warning()

    string_list = _tei_xml_to_list(tei_xml_path,
                                   tags=tags,
                                   subtags=subtags,
                                   errors=errors,
                                   **kwargs
                                   )
    result_text = sep.join(string_list)
    # remove all \s+ to ' '
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


def convert_html_to_single_line_str(html_filepath, strike_tags: typing.Optional[list] = ["s", "strike", "del", "table"],
                                    html_partial=False, suppress_warn=False, errors='backslashreplace', **kwargs):
    """
    The function is based on readability, which is a python package. read a html file to single line string.
    WARNING: It do not read table in html in default, if you want to read table, you should remove the table tag
    from strike_tags.
    Args:
        html_filepath: file path
        strike_tags: the tags of strike html tags, default ["s", "strike", "del", "table"]
        html_partial: return only the div of the document, don't wrap
                             in html and body tags. see readability.Document().summary
        suppress_warn: is or not suppress the warn of sep letter


    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s

    """
    if not suppress_warn:
        __sep_letter_warning()

    # check the input strike_tags
    if not strike_tags:
        pass
    if isinstance(strike_tags, list):
        pass
    elif isinstance(strike_tags, str):
        strike_tags = [strike_tags]
    else:
        raise ValueError('The tag either be string of list')

    encodetype = _BasicKits._BasicFuncT.find_file_encoding(html_filepath) \
        if not _BasicKits._BasicFuncT.find_file_encoding(html_filepath) is None else 'utf-8'
    # Open the HTML file and read it into a string
    with open(html_filepath, 'r', encoding=encodetype, errors=errors) as f:
        html_f = f.read()

    readability_cls = readability.Document(html_f, **kwargs)

    html_content = readability_cls.summary(html_partial)

    # Parse the HTML with BeautifulSoup
    soup = bs4.BeautifulSoup(html_content, 'html.parser')

    # Find and remove all strikethrough text
    if strike_tags:
        try:
            for strike_tag in soup(strike_tags):
                strike_tag.decompose()
        except:
            warnings.warn('decompose of bs4 runs in error, automatically passed', ResourceWarning)

    # Convert the modified HTML to text
    h = html2text.HTML2Text()
    h.ignore_links = True
    result_text = h.handle(str(soup))
    # remove all \s+ to ' '
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


def convert_pdf_to_single_line_str(pdf_file_path, start_index: int = 0, end_index: typing.Optional[int] = None,
                                   suppress_warn=False
                                   ):
    """
    Args:
        pdf_file_path: pdf file path
        start_index: the page index to start reading
        end_index: None default, however if not None must be int, the end index
    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s

    """
    if not suppress_warn:
        __sep_letter_warning()
    # Open the PDF file in binary mode
    with open(pdf_file_path, 'rb') as f:
        # Create a PDF file reader object
        # pdf_reader = PyPDF2.PdfFileReader(f)
        pdf_reader = PyPDF2.PdfReader(f)

        # Initialize an empty string to store the result_text
        result_text = ''

        # Loop through each page in the PDF and add the result_text to the string
        end_index = end_index if end_index else len(pdf_reader.pages)

        # for page_num in range(pdf_reader.getNumPages()):
        for page_num in range(start_index, end_index):
            # page = pdf_reader.getPage(page_num)
            page = pdf_reader.pages[page_num]
            # result_text += page.extractText()
            result_text += page.extract_text()

    # Remove newline characters to make the result_text a single line
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


def convert_doc_to_single_line_str(doc_file_path, suppress_warn=False):
    """
    new version use Libreoffice->soffice to read the txt from doc file.
    Args:
        doc_file_path: read doc file path, need antiword engine

    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s

    """

    if not suppress_warn:
        __sep_letter_warning()
    doc_file = _BasicKits._BasicFuncT.get_absolute_posix_path(doc_file_path)

    # get pure name
    doc_pure_name = os.path.splitext(os.path.basename(doc_file))[0]

    with tempfile.TemporaryDirectory() as temp_dir:
        temp_text_file = os.path.join(temp_dir, f"{doc_pure_name}.txt")

        # Use LibreOffice's soffice command to convert the DOC file to a text file
        subprocess.run(["soffice", "--headless", "--convert-to", "txt:Text", "--outdir", temp_dir, doc_file])

        doc_encoding = _BasicKits._BasicFuncT.find_file_encoding(temp_text_file) \
            if _BasicKits._BasicFuncT.find_file_encoding(temp_text_file) else 'utf-8'

        # Read the converted text fileï¼Œ however, when you successful read, you always convert success.
        with open(temp_text_file, "r", encoding=doc_encoding) as text_file:
            result_text = text_file.read()

        # Remove newline characters to make the text a single line
        result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

        if len(result_text) == 0:
            warnings.warn('Errors occurs for read Nothing from Libre office converted file', UserWarning)

    return result_text


def convert_rtf_to_single_line_str(rtf_file_path, suppress_warn=False):
    """
    Args:
        rtf_file_path: the rtf file path

    Returns: flat string with no \s{2,}, no \n, \t etc include, but only \s

    """
    if not suppress_warn:
        __sep_letter_warning()
    # Convert the RTF file to TXT format
    result_text = pypandoc.convert_file(rtf_file_path, 'plain', format='rtf')

    # Remove newline characters to make the text a single line
    result_text = re.sub(r'\s+', ' ', result_text, flags=re.IGNORECASE | re.DOTALL)

    return result_text


# --------------------------------------------------------------------------
# Pdf part-slicer
# --------------------------------------------------------------------------

def pdf_extract_partof(pdf_read_path, partofpdf_save_path,
                       start_index: int = 0, end_index: typing.Optional[int] = None):
    # Extract pages from 'from_page' to 'to_page'
    with open(pdf_read_path, 'rb') as f:
        # Create a PDF file reader object
        # pdf_reader = PyPDF2.PdfFileReader(f)
        pdf_reader = PyPDF2.PdfReader(f)

        # Create a PDF writer object to save the extracted pages
        """PyPDF2 3.0.0"""
        # pdf_writer = PyPDF2.PdfFileWriter()
        pdf_writer = PyPDF2.PdfWriter()

        # Loop through each page in the PDF and add the result_text to the string
        end_index = end_index if end_index else len(pdf_reader.pages)

        for page_num in range(start_index, end_index):
            # page = pdf_reader.getPage(page_num)
            page = pdf_reader.pages[page_num]
            # result_text += page.extractText()
            """PyPDF2 3.0.0"""
            # pdf_writer.addPage(page=page)
            pdf_writer.add_page(page=page)

        with open(partofpdf_save_path, 'wb') as temp_pdf_file:
            pdf_writer.write(temp_pdf_file)


def pdfs_combine_to_one(pdfs_path_list, combined_pdf_path):
    """
    give a list of pdfs path, combine them to one pdf
    :param pdfs_path_list: the list of pdfs path
    :param combined_pdf_path: the path of combined pdf
    :return: None
    """
    # Create a PDF writer object to save the combined pages
    """PyPDF2 3.0.0"""
    # pdf_writer = PyPDF2.PdfFileWriter()
    pdf_writer = PyPDF2.PdfWriter()

    for pdf_path in pdfs_path_list:
        with open(pdf_path, 'rb') as f:
            # Create a PDF file reader object
            # pdf_reader = PyPDF2.PdfFileReader(f)
            pdf_reader = PyPDF2.PdfReader(f)

            # Loop through each page in the PDF and add the result_text to the string
            for page_num in range(len(pdf_reader.pages)):
                # page = pdf_reader.getPage(page_num)
                page = pdf_reader.pages[page_num]
                # result_text += page.extractText()
                """PyPDF2 3.0.0"""
                # pdf_writer.addPage(page=page)
                pdf_writer.add_page(page=page)

    with open(combined_pdf_path, 'wb') as temp_pdf_file:
        pdf_writer.write(temp_pdf_file)


def count_pdf_pages(pdf_file_path):
    """
    count the pdf pages
    Args:
        pdf_file_path: the pdf file path
    """
    with open(pdf_file_path, 'rb') as f:
        # Create a PDF file reader object
        # pdf_reader = PyPDF2.PdfFileReader(f)
        pdf_reader = PyPDF2.PdfReader(f)
        return len(pdf_reader.pages)


def is_pdf_valid(pdf_file_path):
    """
    check the pdf is valid or not
    Args:
        pdf_file_path: 

    Returns:

    """
    with open(pdf_file_path, 'rb') as f:
        try:
            pdf = PyPDF2.PdfReader(f)
            info = pdf.metadata
            if info:
                return True
            else:
                return False
        except Exception as e:
            return False
